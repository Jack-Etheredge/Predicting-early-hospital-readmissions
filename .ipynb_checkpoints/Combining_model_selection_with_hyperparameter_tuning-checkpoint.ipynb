{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying and predicting early hospital readmissions:\n",
    "\n",
    "Classifying with supervised learning whether diabetic patients are readmitted, and if they are, if it's before or after 30 days.\n",
    "\n",
    "Using the dataset from here: https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:46:54.730708Z",
     "start_time": "2019-10-04T22:46:54.723712Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import patsy as patsy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold, RandomizedSearchCV, train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pickle\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:46:55.266558Z",
     "start_time": "2019-10-04T22:46:54.930969Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"x_liv.pkl\", 'rb') as picklefile:\n",
    "    X = pickle.load(picklefile)\n",
    "\n",
    "with open(\"y_liv.pkl\", 'rb') as picklefile:\n",
    "    y = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:46:55.306117Z",
     "start_time": "2019-10-04T22:46:55.268471Z"
    }
   },
   "outputs": [],
   "source": [
    "y = y.replace({'<30': 1, '>30': 0, 'NO': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:46:55.357683Z",
     "start_time": "2019-10-04T22:46:55.355207Z"
    }
   },
   "outputs": [],
   "source": [
    "# y.head()\n",
    "# set(list(y))\n",
    "# y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:46:55.722751Z",
     "start_time": "2019-10-04T22:46:55.539697Z"
    }
   },
   "outputs": [],
   "source": [
    "# stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:46:56.382900Z",
     "start_time": "2019-10-04T22:46:55.724565Z"
    }
   },
   "outputs": [],
   "source": [
    "# standard scale\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:24.945134Z",
     "start_time": "2019-10-04T22:46:56.385551Z"
    }
   },
   "outputs": [],
   "source": [
    "# smote oversampling\n",
    "smote = SMOTE()\n",
    "X_train, y_train = smote.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T22:47:24.954786Z",
     "start_time": "2019-10-04T22:47:24.947420Z"
    }
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "# models.append(('KNN', KNeighborsClassifier())) # can take a very long time\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('ETC', ExtraTreesClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('ADA', AdaBoostClassifier()))\n",
    "models.append(('GBM', GradientBoostingClassifier()))\n",
    "# models.append(('SVM', SVC())) # can take a very long time\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:46:56.277Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.634865 (0.016725)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.633105 (0.016809)\n",
      "DT: 0.861213 (0.139239)\n",
      "NB: 0.668586 (0.000482)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETC: 0.937967 (0.109162)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: 0.904494 (0.175557)\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=5, random_state=42)\n",
    "    cv_results = cross_val_score(\n",
    "        model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:48:13.653Z"
    }
   },
   "outputs": [],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:48:18.140Z"
    }
   },
   "outputs": [],
   "source": [
    "# Best model was extra trees:\n",
    "\n",
    "param_grid = {'n_estimators': range(50, 126, 25),\n",
    "              'max_features': range(50, X.shape[1], 50),\n",
    "              'min_samples_leaf': range(20, 50, 5),\n",
    "              'min_samples_split': range(15, 36, 5)}\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=100, n_jobs=-1, min_samples_split=25,\n",
    "                             min_samples_leaf=35, max_features=150)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:48:18.323Z"
    }
   },
   "outputs": [],
   "source": [
    "def grid_or_random_cv(grid_or_random='random'):\n",
    "    if grid_or_random == 'grid':\n",
    "        grid_search = GridSearchCV(estimator=model,\n",
    "                                   param_grid=param_grid,\n",
    "                                   scoring='f1',\n",
    "                                   cv=kfold)\n",
    "\n",
    "        grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "    if grid_or_random == 'random':\n",
    "        n_iter_search = 25\n",
    "\n",
    "        random_search = RandomizedSearchCV(estimator=model,\n",
    "                                           param_distributions=param_grid,\n",
    "                                           scoring='roc_auc',\n",
    "                                           n_iter=n_iter_search,\n",
    "                                           cv=kfold)\n",
    "\n",
    "        grid_result = random_search.fit(X_train, y_train)\n",
    "\n",
    "    return grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:48:18.502Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_result = grid_or_random_cv(grid_or_random='random')\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:48:21.236Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (test_mean, test_std, param) in enumerate(zip(\n",
    "        grid_result.cv_results_['mean_test_score'],\n",
    "        grid_result.cv_results_['std_test_score'],\n",
    "        grid_result.cv_results_['params'])):\n",
    "    print(\"%i Test avg: %f \\n Test std: %f with: \\n %r\" %\n",
    "          (i, test_mean, test_std, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:48:22.332Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier(**grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:48:22.988Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:48:23.852Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:48:24.140Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:48:26.612Z"
    }
   },
   "outputs": [],
   "source": [
    "# import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:48:28.700Z"
    }
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:50:46.902Z"
    }
   },
   "outputs": [],
   "source": [
    "def precision_recall_plot(y_test, y_pred_proba):\n",
    "    p, r, t = precision_recall_curve(y_test, y_pred_proba[:, 1])\n",
    "\n",
    "    # adding last threshold of '1' to threshold list\n",
    "    t = np.vstack([t.reshape([-1, 1]), 1])\n",
    "    \n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.suptitle('Precision Recall Curve')\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(t, p, label=\"precision\")\n",
    "    plt.plot(t, r, label=\"recall\")\n",
    "    plt.show()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:50:48.248Z"
    }
   },
   "outputs": [],
   "source": [
    "precision_recall_plot(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:54:05.639Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = [\"not early readmit\", \"early readmit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:54:05.935Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=sns.color_palette(\"Blues\")):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Only use the labels that appear in the data\n",
    "#     classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = sns.heatmap(cm, cmap = cmap, annot=True, xticklabels=classes, yticklabels=classes)\n",
    "\n",
    "    ax.set(title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the x labels and set their alignment\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Vertically center y labels\n",
    "    plt.setp(ax.get_yticklabels(), va=\"center\")\n",
    "    \n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:54:06.703Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "ax = plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# plt.savefig('confusion_matrix_test.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-04T22:54:07.016Z"
    }
   },
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining grid search and model selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, **grid_kwargs):\n",
    "        for key in self.keys:\n",
    "            print('Running GridSearchCV for %s.' % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            grid_search = GridSearchCV(model, params, **grid_kwargs)\n",
    "            grid_search.fit(X, y)\n",
    "            self.grid_searches[key] = grid_search\n",
    "        print('Done.')\n",
    "\n",
    "    def score_summary(self, sort_by='mean_test_score'):\n",
    "        frames = []\n",
    "        for name, grid_search in self.grid_searches.items():\n",
    "            frame = pd.DataFrame(grid_search.cv_results_)\n",
    "            frame = frame.filter(regex='^(?!.*param_).*$')\n",
    "            frame['estimator'] = len(frame)*[name]\n",
    "            frames.append(frame)\n",
    "        df = pd.concat(frames)\n",
    "\n",
    "        df = df.sort_values([sort_by], ascending=False)\n",
    "        df = df.reset_index()\n",
    "        df = df.drop(['rank_test_score', 'index'], 1)\n",
    "\n",
    "        columns = df.columns.tolist()\n",
    "        columns.remove('estimator')\n",
    "        columns = ['estimator']+columns\n",
    "        df = df[columns]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'ExtraTreesClassifier': {'n_estimators': [16, 32]},\n",
    "    'RandomForestClassifier': [\n",
    "        {'n_estimators': [16, 32]},\n",
    "        {'criterion': ['gini', 'entropy'], 'n_estimators': [8, 16]}],\n",
    "    'AdaBoostClassifier':  {'n_estimators': [16, 32]},\n",
    "    'GradientBoostingClassifier': {'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = EstimatorSelectionHelper(models, params)\n",
    "helper.fit(X, y, scoring='f1', n_jobs=-1)\n",
    "helper.fit(X, y, scoring='neg_log_loss', n_jobs=-1)\n",
    "helper.score_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
